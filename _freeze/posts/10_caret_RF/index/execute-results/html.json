{
  "hash": "7c22110ae6c7cac476f87634ce2f8a05",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Random Forest with Caret\"\nauthor: \"Jie Wu\"\ndraft: false\ndate: \"2025-06-19\"\nformat: \n    html:\n        toc: true\n        toc-depth: 2\n        code-fold: false\ncategories: [\"Machine Learning\", \"Data Science\", \"R Programming\"]\n---\n\nIn this post, we will use the `caret` package to implement a more standardized machine learning workflow. \n\nThe `caret` (Classification And REgression Training) package in R is a comprehensive toolkit for building, evaluating, and tuning machine learning models. It provides a unified interface to hundreds of algorithms, streamlines data preprocessing, supports resampling methods, and simplifies model comparison. By standardizing workflows, `caret` makes it easier to develop robust and reproducible predictive models in R. \n\nLet's load the prepare the data table again:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load all packages\nrequire(tidyverse)\nrequire(here)\nrequire(caret) \n\n# Load the mutation table from the RDS file saved in the last post\ndata <- readRDS(here(\"_data/combined_data.rds\"))\n\nfile_path <- here(\"_data/cancerGeneList.tsv\")\n\nGene_anno <- read_tsv(file_path, guess_max = Inf)\n\n# pull genes in MSK-IMPACT panel \n\nMSK_genes <- Gene_anno %>% filter(`MSK-IMPACT` == \"Yes\") %>%\n            pull(`Hugo Symbol`) %>% unique()\n\ndata_rf <- data %>% \n        dplyr::select(any_of(paste0(\"mut.\", MSK_genes)),\n                                    WGD) %>%\n                filter(! is.na(WGD))\n\n# remove \"-\" from names to avoid errors running RF               \nnames(data_rf) <- gsub(\"-\", \"\", names(data_rf))\n\ndata_rf <- data_rf %>% mutate(WGD = as.factor(WGD))\n```\n:::\n\n\n`caret` has handy functions to create training and test sets easily. We can use the `createDataPartition()` function to split our data into training and testing sets while preserving the class distribution of the target variable. We can then use `trainControl()` to set up cross-validation parameteres. \n\nHere's how we can do it: (The training will take a while)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(23)\ntrain_idx <- createDataPartition(data_rf$WGD, p = 0.8, list = FALSE)\ntrain_data <- data_rf[train_idx, ]\ntest_data <- data_rf[-train_idx, ]\n\n# Set up cross-validation\nctrl <- trainControl(method = \"cv\", number = 10)\n\nrf_model <- train(\n    WGD ~ .,\n    data = train_data,\n    method = \"rf\",\n    trControl = ctrl,\n    importance = TRUE\n)\n\n\nprint(rf_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRandom Forest \n\n1286 samples\n 475 predictor\n   2 classes: '0', '1' \n\nNo pre-processing\nResampling: Cross-Validated (10 fold) \nSummary of sample sizes: 1158, 1157, 1157, 1158, 1157, 1157, ... \nResampling results across tuning parameters:\n\n  mtry  Accuracy   Kappa    \n    2   0.6609738  0.0000000\n  238   0.6570494  0.2494827\n  475   0.6500484  0.2411229\n\nAccuracy was used to select the optimal model using the largest value.\nThe final value used for the model was mtry = 2.\n```\n\n\n:::\n\n```{.r .cell-code}\nrandomForest::varImpPlot(rf_model$finalModel, n.var=10)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Predict on test set\nrf_pred <- predict(rf_model, newdata = test_data)\n\nconfusionMatrix(rf_pred, test_data$WGD)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0   0   0\n         1 109 212\n                                          \n               Accuracy : 0.6604          \n                 95% CI : (0.6058, 0.7121)\n    No Information Rate : 0.6604          \n    P-Value [Acc > NIR] : 0.526           \n                                          \n                  Kappa : 0               \n                                          \n Mcnemar's Test P-Value : <2e-16          \n                                          \n            Sensitivity : 0.0000          \n            Specificity : 1.0000          \n         Pos Pred Value :    NaN          \n         Neg Pred Value : 0.6604          \n             Prevalence : 0.3396          \n         Detection Rate : 0.0000          \n   Detection Prevalence : 0.0000          \n      Balanced Accuracy : 0.5000          \n                                          \n       'Positive' Class : 0               \n                                          \n```\n\n\n:::\n:::\n\n\nLet's take a look at top features, we use `ComplexHeatmap`, which is my favorite heatmap package. We only use a subset of the cell lines for better visualiztion.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntopfeatures <- \n    randomForest::importance(rf_model$finalModel)  %>% \n    as.data.frame() %>% \n    arrange(-`0`) %>% \n    head(10)  %>% \n    row.names()\n\nrequire(ComplexHeatmap)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: ComplexHeatmap\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: grid\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n========================================\nComplexHeatmap version 2.24.0\nBioconductor page: http://bioconductor.org/packages/ComplexHeatmap/\nGithub page: https://github.com/jokergoo/ComplexHeatmap\nDocumentation: http://jokergoo.github.io/ComplexHeatmap-reference\n\nIf you use it in published research, please cite either one:\n- Gu, Z. Complex Heatmap Visualization. iMeta 2022.\n- Gu, Z. Complex heatmaps reveal patterns and correlations in multidimensional \n    genomic data. Bioinformatics 2016.\n\n\nThe new InteractiveComplexHeatmap package can directly export static \ncomplex heatmaps into an interactive Shiny app with zero effort. Have a try!\n\nThis message can be suppressed by:\n  suppressPackageStartupMessages(library(ComplexHeatmap))\n========================================\n```\n\n\n:::\n\n```{.r .cell-code}\nHeatmap(\n    data_rf %>% arrange(WGD) %>% dplyr::select(topfeatures),\n    left_annotation = HeatmapAnnotation(\n        df = (data_rf %>% arrange(WGD) %>% dplyr::select(WGD)),\n        which = \"row\"\n    ),\n    cluster_rows = FALSE,\n    border = FALSE,\n    col = c(\"0\" = \"white\", \"1\" = \"red\")\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Using an external vector in selections was deprecated in tidyselect 1.1.0.\nâ„¹ Please use `all_of()` or `any_of()` instead.\n  # Was:\n  data %>% select(topfeatures)\n\n  # Now:\n  data %>% select(all_of(topfeatures))\n\nSee <https://tidyselect.r-lib.org/reference/faq-external-vector.html>.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: The input is a data frame-like object, convert it to a matrix.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}