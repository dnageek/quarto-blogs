{
  "hash": "92737a4b17998f9c39d72a6f5ac51846",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Recursive Feature Elimination with Caret\"\nauthor: \"Jie Wu\"\ndraft: false\ndate: \"2025-06-21\"\nformat: \n    html:\n        toc: true\n        toc-depth: 2\n        code-fold: false\ncategories: [\"Machine Learning\", \"Data Science\", \"R Programming\"]\n---\n\nIn this post, we will do something slightly more complicated with `caret`. Recursive Feature Elimination (RFE) is a feature selection technique that recursively removes less important features and builds models on the remaining subset of features. The goal is to identify the most relevant features that contribute to the predictive performance of the model. \n\nThe first section of the code will be the same:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load all packages\nrequire(tidyverse)\nrequire(here)\nrequire(caret) \nrequire(randomForest)\n\n# Load the mutation table from the RDS file saved in the last post\ndata <- readRDS(here(\"_data/combined_data.rds\"))\n\nfile_path <- here(\"_data/cancerGeneList.tsv\")\n\nGene_anno <- read_tsv(file_path, guess_max = Inf)\n\n# pull genes in MSK-IMPACT panel \n\nMSK_genes <- Gene_anno %>% filter(`MSK-IMPACT` == \"Yes\") %>%\n            pull(`Hugo Symbol`) %>% unique()\n\ndata_rf <- data %>% \n        dplyr::select(any_of(paste0(\"mut.\", MSK_genes)),\n                                    WGD) %>%\n                filter(! is.na(WGD))\n\n# remove \"-\" from names to avoid errors running RF               \nnames(data_rf) <- gsub(\"-\", \"\", names(data_rf))\n\ndata_rf <- data_rf %>% mutate(WGD = as.factor(WGD))\n```\n:::\n\n\nLet's now run RFE, still with Ramdom Forests. It will take a while too...\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(23)\ntrain_idx <- createDataPartition(data_rf$WGD, p = 0.8, list = FALSE)\ntrain_data <- data_rf[train_idx, ]\ntest_data <- data_rf[-train_idx, ]\n\n# Set up RFE\nrfe_control <-rfeControl(functions = rfFuncs, \n                   method = \"repeatedcv\", \n                   number = 10,\n                   repeats = 3,\n                   verbose = FALSE)\n\nrfe_result <- rfe(\n  x = train_data %>% dplyr::select(-WGD),\n  y = train_data$WGD,\n  sizes = c(5,10,20,30,40,50,100), \n  rfeControl = rfe_control )\n\nprint(rfe_result)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nRecursive feature selection\n\nOuter resampling method: Cross-Validated (10 fold, repeated 3 times) \n\nResampling performance over subset size:\n\n Variables Accuracy   Kappa AccuracySD KappaSD Selected\n         5   0.6578 0.09567    0.02716 0.09121         \n        10   0.6620 0.23667    0.03135 0.10668         \n        20   0.6825 0.30673    0.04058 0.09377         \n        30   0.6897 0.32485    0.04305 0.09323         \n        40   0.6931 0.32918    0.04620 0.09903         \n        50   0.6967 0.33438    0.04392 0.09383         \n       100   0.6993 0.33601    0.04499 0.09349         \n       475   0.7089 0.35307    0.04247 0.08988        *\n\nThe top 5 variables (out of 475):\n   mut.TP53, mut.ID3, mut.NF1, mut.CCND3, mut.ASXL1\n```\n\n\n:::\n\n```{.r .cell-code}\nrfe_final_model <- rfe_result$fit\n\nvarImpPlot(rfe_final_model, n.var=15)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Predict on test set\nrf_pred <- predict(rfe_final_model, newdata = test_data)\n\nconfusionMatrix(rf_pred, test_data$WGD)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0  47  39\n         1  62 173\n                                          \n               Accuracy : 0.6854          \n                 95% CI : (0.6315, 0.7358)\n    No Information Rate : 0.6604          \n    P-Value [Acc > NIR] : 0.18874         \n                                          \n                  Kappa : 0.2606          \n                                          \n Mcnemar's Test P-Value : 0.02859         \n                                          \n            Sensitivity : 0.4312          \n            Specificity : 0.8160          \n         Pos Pred Value : 0.5465          \n         Neg Pred Value : 0.7362          \n             Prevalence : 0.3396          \n         Detection Rate : 0.1464          \n   Detection Prevalence : 0.2679          \n      Balanced Accuracy : 0.6236          \n                                          \n       'Positive' Class : 0               \n                                          \n```\n\n\n:::\n:::\n\n\nApparently, using all features to build a model is not ideal and likely to be overfitting. But as a toy example, we can see the top feature is mut.TP53, which has been reported to be associated with WGD status.",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}